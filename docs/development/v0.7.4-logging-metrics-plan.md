# v0.7.4 - Logging, Metrics & Kill-Switch Improvements

## Overview
This document outlines comprehensive improvements to logging, Prometheus metrics, and kill-switch functionality for v0.7.4.

**Status**: Planning
**Target Release**: v0.7.4
**Estimated Effort**: 2-3 weeks
**Code Changes**: ~380 lines across 8 files

---

## Executive Summary

**Current State Analysis** (from comprehensive codebase review):
- ✅ Logging: Good coverage in network operations, missing in critical path
- ⚠️  Metrics: Defined but mostly not recorded (only 3/12 metrics used)
- ✅ Kill-Switches: Working well, but lack duration/scheduling support
- ❌ Integration: Metrics not passed to components that need them

**Key Findings**:
1. **Metrics Gap**: DNSCacheHits, DNSCacheMisses, DNSBlockedQueries, DNSForwardedQueries, BlocklistSize, CacheSize are defined but never recorded
2. **Logging Gap**: Policy evaluation, cache operations, and storage queries lack visibility
3. **Kill-Switch Gap**: No support for temporary disable (duration-based)

---

## Phase 1: Critical Metrics (P0) - Week 1

### Goal
Record essential metrics that users need for monitoring production systems.

### 1.1 Record DNSBlockedQueries Metric

**File**: `pkg/dns/server.go`

**Changes**:
```go
// Line 499 - After policy BLOCK action
case policy.ActionBlock:
    blocked = true
    responseCode = dns.RcodeNameError
    msg.SetRcode(r, dns.RcodeNameError)

    // NEW: Record blocked query metric
    if h.Metrics != nil {
        h.Metrics.DNSBlockedQueries.Add(ctx, 1)
    }

    h.writeMsg(w, msg)
    return

// Line 632 - After blocklist check
if blocked {
    responseCode = dns.RcodeNameError
    msg.SetRcode(r, dns.RcodeNameError)

    // NEW: Record blocked query metric
    if h.Metrics != nil {
        h.Metrics.DNSBlockedQueries.Add(ctx, 1)
    }

    h.writeMsg(w, msg)
    return
}

// Line 742 - After legacy blocklist check
if blocked {
    responseCode = dns.RcodeNameError
    msg.SetRcode(r, dns.RcodeNameError)

    // NEW: Record blocked query metric
    if h.Metrics != nil {
        h.Metrics.DNSBlockedQueries.Add(ctx, 1)
    }

    h.writeMsg(w, msg)
    return
}
```

**Add Metrics field to Handler**:
```go
// pkg/dns/server.go
type Handler struct {
    Storage          storage.Storage
    BlocklistManager *blocklist.Manager
    Blocklist        map[string]struct{}
    Whitelist        map[string]struct{}
    Overrides        map[string]net.IP
    CNAMEOverrides   map[string]string
    LocalRecords     *localrecords.Manager
    PolicyEngine     *policy.Engine
    RuleEvaluator    *forwarder.RuleEvaluator
    Forwarder        *forwarder.Forwarder
    Cache            *cache.Cache
    ConfigWatcher    *config.Watcher
    Metrics          *telemetry.Metrics  // NEW
    lookupMu         sync.RWMutex
}

// Add setter method
func (h *Handler) SetMetrics(m *telemetry.Metrics) {
    h.Metrics = m
}
```

**Update main.go**:
```go
// cmd/glory-hole/main.go
handler := dns.NewHandler()
// ... other setters ...
handler.SetMetrics(metrics)  // NEW
```

### 1.2 Record DNSForwardedQueries Metric

**File**: `pkg/dns/server.go`

**Changes**:
```go
// Line 508 - After policy ALLOW forward
if h.Forwarder != nil {
    resp, err := h.Forwarder.Forward(ctx, r)
    if err != nil {
        responseCode = dns.RcodeServerFailure
        msg.SetRcode(r, dns.RcodeServerFailure)
        h.writeMsg(w, msg)
        return
    }

    // Track upstream server
    upstreams := h.Forwarder.Upstreams()
    if len(upstreams) > 0 {
        upstream = upstreams[0]
    }

    // NEW: Record forwarded query metric
    if h.Metrics != nil {
        h.Metrics.DNSForwardedQueries.Add(ctx, 1)
    }

    // Cache the response
    if h.Cache != nil {
        h.Cache.Set(ctx, r, resp)
    }

    responseCode = resp.Rcode
    h.writeMsg(w, resp)
    return
}

// Similar additions at:
// - Line 600 (policy FORWARD action)
// - Line 806 (conditional forwarding)
// - Line 833 (default upstream forwarding)
```

**Impact**:
- Users can monitor upstream server usage
- Troubleshoot forwarding issues
- Capacity planning for upstream bandwidth

---

## Phase 2: Cache & Blocklist Metrics (P1) - Week 1-2

### 2.1 Record Cache Metrics

**File**: `pkg/cache/cache.go`

**Add Metrics field**:
```go
type Cache struct {
    cfg         *config.CacheConfig
    logger      *logging.Logger
    metrics     *telemetry.Metrics  // NEW
    entries     map[string]*cacheEntry
    stopCleanup chan struct{}
    cleanupDone chan struct{}
    stats       cacheStats
    maxEntries  int
    mu          sync.RWMutex
}

// Update constructor
func New(cfg *config.CacheConfig, logger *logging.Logger, metrics *telemetry.Metrics) (*Cache, error) {
    // ...
    c := &Cache{
        cfg:         cfg,
        logger:      logger,
        metrics:     metrics,  // NEW
        // ...
    }
    // ...
}
```

**Record cache hits/misses**:
```go
// Line 113 - Cache miss (not found)
if entry == nil {
    c.recordMiss()

    // NEW: Record Prometheus metric
    if c.metrics != nil {
        c.metrics.DNSCacheMisses.Add(ctx, 1)
    }

    return nil
}

// Line 120 - Cache miss (expired)
if time.Now().After(entry.expiresAt) {
    c.recordMiss()
    delete(c.entries, key)

    // NEW: Record Prometheus metric
    if c.metrics != nil {
        c.metrics.DNSCacheMisses.Add(ctx, 1)
    }

    return nil
}

// Line 134 - Cache hit
c.recordHit()
entry.lastAccess = time.Now()

// NEW: Record Prometheus metric
if c.metrics != nil {
    c.metrics.DNSCacheHits.Add(ctx, 1)
}

return entry.msg.Copy()
```

**Record cache size**:
```go
// Line 177 - After Set()
c.entries[key] = entry
c.stats.sets++

// NEW: Update cache size gauge
if c.metrics != nil {
    c.metrics.CacheSize.Add(ctx, 1)
}

// Line 247 - After LRU eviction
delete(c.entries, oldestKey)
c.stats.evictions++

// NEW: Update cache size gauge
if c.metrics != nil {
    c.metrics.CacheSize.Add(ctx, -1)
}

// Line 316 - On Clear()
count := len(c.entries)
c.entries = make(map[string]*cacheEntry, c.maxEntries)
c.stats = cacheStats{}

// NEW: Update cache size gauge
if c.metrics != nil {
    c.metrics.CacheSize.Add(ctx, -int64(count))
}
```

### 2.2 Record Blocklist Metrics

**File**: `pkg/blocklist/manager.go`

**Add Metrics field**:
```go
type Manager struct {
    cfg     *config.Config
    logger  *logging.Logger
    metrics *telemetry.Metrics  // NEW
    current atomic.Pointer[blocklistData]
    stopUpdate chan struct{}
    updateDone chan struct{}
}

// Update constructor
func NewManager(cfg *config.Config, logger *logging.Logger, metrics *telemetry.Metrics) *Manager {
    m := &Manager{
        cfg:        cfg,
        logger:     logger,
        metrics:    metrics,  // NEW
        stopUpdate: make(chan struct{}),
        updateDone: make(chan struct{}),
    }
    // ...
}
```

**Record blocklist size**:
```go
// Line 115 - After Update()
m.current.Store(&newData)
m.logger.Info("Blocklist updated",
    "total_domains", len(newData.domains),
    "sources", len(m.cfg.Blocklists),
    "duration_ms", time.Since(startTime).Milliseconds(),
)

// NEW: Update blocklist size gauge
if m.metrics != nil {
    m.metrics.BlocklistSize.Add(ctx, int64(len(newData.domains)))

    // Also remove previous count
    if prevData := m.current.Load(); prevData != nil {
        m.metrics.BlocklistSize.Add(ctx, -int64(len(prevData.domains)))
    }
}

return nil

// Line 40 - On initialization
data := &blocklistData{
    domains: make(map[string]struct{}, 100000),
    updated: time.Now(),
}
m.current.Store(data)

// Download initial blocklists
if err := m.Update(); err != nil {
    m.logger.Error("Initial blocklist download failed", "error", err)
    // Don't fail initialization - blocklist will be updated later
}

// NEW: Record initial size
if m.metrics != nil && m.current.Load() != nil {
    m.metrics.BlocklistSize.Add(context.Background(), int64(len(m.current.Load().domains)))
}
```

**Update main.go**:
```go
// Pass metrics to constructors
cache, err := cache.New(&cfg.Cache, logger, metrics)
blocklistMgr := blocklist.NewManager(cfg, logger, metrics)
```

---

## Phase 3: Enhanced Logging (P2) - Week 2

### 3.1 Policy Engine Logging

**File**: `pkg/policy/engine.go`

```go
// Line 165 - In Evaluate()
func (e *Engine) Evaluate(ctx *Context) (bool, *Rule) {
    e.mu.RLock()
    defer e.mu.RUnlock()

    for _, rule := range e.rules {
        if !rule.Enabled {
            continue
        }

        result, err := vm.Run(rule.program, ctx)
        if err != nil {
            // NEW: Log evaluation errors
            slog.Error("Policy rule evaluation failed",
                "rule", rule.Name,
                "error", err,
                "domain", ctx.Domain,
                "client", ctx.ClientIP,
            )
            continue
        }

        if matched, ok := result.(bool); ok && matched {
            // NEW: Log rule matches
            slog.Info("Policy rule matched",
                "rule", rule.Name,
                "action", rule.Action,
                "domain", ctx.Domain,
                "client", ctx.ClientIP,
            )
            return true, rule
        }
    }

    return false, nil
}
```

### 3.2 DNS Policy Action Logging

**File**: `pkg/dns/server.go`

```go
// Line 506 - ALLOW action
case policy.ActionAllow:
    // NEW: Log policy action
    if h.Logger != nil {
        h.Logger.Info("Policy ALLOW action",
            "rule", rule.Name,
            "domain", strings.TrimSuffix(domain, "."),
            "client", clientIP,
        )
    }

    if h.Forwarder != nil {
        // ... existing code ...
    }

// Line 549 - REDIRECT action
case policy.ActionRedirect:
    // NEW: Log policy action
    if h.Logger != nil {
        h.Logger.Info("Policy REDIRECT action",
            "rule", rule.Name,
            "domain", strings.TrimSuffix(domain, "."),
            "redirect_ip", rule.ActionData,
            "client", clientIP,
        )
    }

    redirectIP := net.ParseIP(rule.ActionData)
    // ... existing code ...

// Line 600 - FORWARD action
case policy.ActionForward:
    // NEW: Log policy action
    if h.Logger != nil {
        h.Logger.Info("Policy FORWARD action",
            "rule", rule.Name,
            "domain", strings.TrimSuffix(domain, "."),
            "upstreams", rule.GetUpstreams(),
            "client", clientIP,
        )
    }

    upstreams := rule.GetUpstreams()
    // ... existing code ...
```

**Add Logger field to Handler**:
```go
type Handler struct {
    Storage          storage.Storage
    BlocklistManager *blocklist.Manager
    Blocklist        map[string]struct{}
    Whitelist        map[string]struct{}
    Overrides        map[string]net.IP
    CNAMEOverrides   map[string]string
    LocalRecords     *localrecords.Manager
    PolicyEngine     *policy.Engine
    RuleEvaluator    *forwarder.RuleEvaluator
    Forwarder        *forwarder.Forwarder
    Cache            *cache.Cache
    ConfigWatcher    *config.Watcher
    Metrics          *telemetry.Metrics
    Logger           *logging.Logger  // NEW
    lookupMu         sync.RWMutex
}
```

### 3.3 Storage Error Logging

**File**: `pkg/storage/sqlite.go`

```go
// Example for GetRecentQueries (Line 301)
func (s *SQLiteStorage) GetRecentQueries(ctx context.Context, limit int) ([]*QueryLog, error) {
    query := `
        SELECT timestamp, client_ip, domain, query_type, response_code,
               blocked, cached, response_time_ms, upstream
        FROM query_logs
        ORDER BY timestamp DESC
        LIMIT ?
    `

    rows, err := s.db.QueryContext(ctx, query, limit)
    if err != nil {
        // NEW: Add error logging
        s.logger.Error("Failed to query recent queries",
            "error", err,
            "limit", limit,
        )
        return nil, fmt.Errorf("failed to query recent logs: %w", err)
    }
    defer rows.Close()

    // ... rest of function ...
}

// Apply similar pattern to all Get* methods:
// - GetQueriesByDomain
// - GetQueriesByClientIP
// - GetStatistics
// - GetTopDomains
// - GetBlockedCount
// - GetQueryCount
```

---

## Phase 4: Duration-Based Kill-Switches (P3) - Week 3

### 4.1 Configuration Schema

**File**: `pkg/config/config.go`

```go
type ServerConfig struct {
    ListenAddress   string        `yaml:"listen_address"`
    WebUIAddress    string        `yaml:"web_ui_address"`
    TCPEnabled      bool          `yaml:"tcp_enabled"`
    UDPEnabled      bool          `yaml:"udp_enabled"`
    EnableBlocklist bool          `yaml:"enable_blocklist"`
    EnablePolicies  bool          `yaml:"enable_policies"`

    // NEW: Duration-based kill-switches
    BlocklistDisableUntil *time.Time    `yaml:"blocklist_disable_until,omitempty"` // Absolute time
    BlocklistDisableFor   time.Duration `yaml:"blocklist_disable_for,omitempty"`   // Relative duration
    PoliciesDisableUntil  *time.Time    `yaml:"policies_disable_until,omitempty"`
    PoliciesDisableFor    time.Duration `yaml:"policies_disable_for,omitempty"`
}
```

### 4.2 Kill-Switch Evaluation Logic

**File**: `pkg/dns/server.go`

```go
// Line 476 - Update kill-switch check
enablePolicies := true
enableBlocklist := true
if h.ConfigWatcher != nil {
    cfg := h.ConfigWatcher.Config()

    // Check boolean kill-switch
    enablePolicies = cfg.Server.EnablePolicies
    enableBlocklist = cfg.Server.EnableBlocklist

    // NEW: Check time-based kill-switch
    now := time.Now()

    // Check blocklist disable until
    if cfg.Server.BlocklistDisableUntil != nil && now.Before(*cfg.Server.BlocklistDisableUntil) {
        enableBlocklist = false

        if h.Logger != nil {
            h.Logger.Debug("Blocklist disabled by time-based kill-switch",
                "until", cfg.Server.BlocklistDisableUntil,
                "remaining", cfg.Server.BlocklistDisableUntil.Sub(now),
            )
        }
    }

    // Check policies disable until
    if cfg.Server.PoliciesDisableUntil != nil && now.Before(*cfg.Server.PoliciesDisableUntil) {
        enablePolicies = false

        if h.Logger != nil {
            h.Logger.Debug("Policies disabled by time-based kill-switch",
                "until", cfg.Server.PoliciesDisableUntil,
                "remaining", cfg.Server.PoliciesDisableUntil.Sub(now),
            )
        }
    }
}
```

### 4.3 API Endpoints

**File**: `pkg/api/handlers_features.go`

```go
// NEW: Structure for duration-based toggle
type FeatureToggleRequest struct {
    BlocklistEnabled bool   `json:"blocklist_enabled"`
    PoliciesEnabled  bool   `json:"policies_enabled"`
    Duration         string `json:"duration,omitempty"`  // e.g., "5m", "1h", "2h30m"
}

// Update handleUpdateFeatures
func (s *Server) handleUpdateFeatures(w http.ResponseWriter, r *http.Request) {
    var req FeatureToggleRequest
    if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
        http.Error(w, "Invalid request body", http.StatusBadRequest)
        return
    }

    // Parse duration if provided
    var disableUntil *time.Time
    if req.Duration != "" {
        duration, err := time.ParseDuration(req.Duration)
        if err != nil {
            http.Error(w, "Invalid duration format", http.StatusBadRequest)
            return
        }

        t := time.Now().Add(duration)
        disableUntil = &t
    }

    // Update config
    cfg := s.configWatcher.Config()

    if disableUntil != nil {
        // Temporary disable
        if !req.BlocklistEnabled {
            cfg.Server.BlocklistDisableUntil = disableUntil
            s.logger.Info("Blocklist temporarily disabled",
                "until", disableUntil,
                "duration", req.Duration,
            )
        }
        if !req.PoliciesEnabled {
            cfg.Server.PoliciesDisableUntil = disableUntil
            s.logger.Info("Policies temporarily disabled",
                "until", disableUntil,
                "duration", req.Duration,
            )
        }
    } else {
        // Permanent toggle
        cfg.Server.EnableBlocklist = req.BlocklistEnabled
        cfg.Server.EnablePolicies = req.PoliciesEnabled
        cfg.Server.BlocklistDisableUntil = nil
        cfg.Server.PoliciesDisableUntil = nil
    }

    // Save config
    if err := cfg.Save(s.configPath); err != nil {
        s.logger.Error("Failed to save config", "error", err)
        http.Error(w, "Failed to save configuration", http.StatusInternalServerError)
        return
    }

    // Config watcher will automatically reload
    w.WriteHeader(http.StatusOK)
    json.NewEncoder(w).Encode(map[string]string{
        "status": "success",
    })
}
```

### 4.4 Auto-Cleanup of Expired Timers

**File**: `pkg/config/watcher.go`

```go
// NEW: Add cleanup goroutine to watcher
func (w *Watcher) startExpirationCheck() {
    go func() {
        ticker := time.NewTicker(1 * time.Minute)
        defer ticker.Stop()

        for {
            select {
            case <-ticker.C:
                w.checkExpirations()
            case <-w.stopChan:
                return
            }
        }
    }()
}

func (w *Watcher) checkExpirations() {
    cfg := w.Config()
    changed := false
    now := time.Now()

    // Check blocklist expiration
    if cfg.Server.BlocklistDisableUntil != nil && now.After(*cfg.Server.BlocklistDisableUntil) {
        w.logger.Info("Blocklist kill-switch expired, re-enabling")
        cfg.Server.BlocklistDisableUntil = nil
        cfg.Server.EnableBlocklist = true
        changed = true
    }

    // Check policies expiration
    if cfg.Server.PoliciesDisableUntil != nil && now.After(*cfg.Server.PoliciesDisableUntil) {
        w.logger.Info("Policies kill-switch expired, re-enabling")
        cfg.Server.PoliciesDisableUntil = nil
        cfg.Server.EnablePolicies = true
        changed = true
    }

    if changed {
        // Save config
        if err := cfg.Save(w.path); err != nil {
            w.logger.Error("Failed to save config after expiration", "error", err)
        }
    }
}
```

### 4.5 Kill-Switch Metrics

**File**: `pkg/telemetry/telemetry.go`

```go
// Add to Metrics struct
type Metrics struct {
    // ... existing metrics ...

    // NEW: Kill-switch metrics
    KillSwitchBlocklistState metric.Int64UpDownCounter
    KillSwitchPoliciesState  metric.Int64UpDownCounter
    KillSwitchToggles        metric.Int64Counter
}

// Add to InitMetrics()
killSwitchBlocklistState, err := meter.Int64UpDownCounter(
    "killswitch.blocklist.state",
    metric.WithDescription("Current blocklist kill-switch state (0=disabled, 1=enabled)"),
)

killSwitchPoliciesState, err := meter.Int64UpDownCounter(
    "killswitch.policies.state",
    metric.WithDescription("Current policies kill-switch state (0=disabled, 1=enabled)"),
)

killSwitchToggles, err := meter.Int64Counter(
    "killswitch.toggles",
    metric.WithDescription("Number of kill-switch state changes"),
)
```

**Record kill-switch state changes**:
```go
// In handlers_features.go after updating config
if req.BlocklistEnabled != cfg.Server.EnableBlocklist {
    metrics.KillSwitchToggles.Add(ctx, 1)

    if req.BlocklistEnabled {
        metrics.KillSwitchBlocklistState.Add(ctx, 1)
    } else {
        metrics.KillSwitchBlocklistState.Add(ctx, -1)
    }
}
```

---

## Testing Strategy

### Unit Tests

1. **Metrics Recording Tests**
   - Verify metrics are incremented correctly
   - Test with nil metrics (graceful handling)
   - Test metric values after operations

2. **Duration Kill-Switch Tests**
   - Test absolute time (disable until)
   - Test relative duration (disable for)
   - Test expiration cleanup
   - Test API endpoint parsing

3. **Logging Tests**
   - Verify log messages are generated
   - Test log levels (DEBUG, INFO, ERROR)
   - Test structured logging fields

### Integration Tests

1. **End-to-End Metrics Test**
   - Start server with metrics enabled
   - Perform DNS queries
   - Scrape `/metrics` endpoint
   - Verify all metrics present

2. **Kill-Switch Duration Test**
   - Disable feature for 5 seconds
   - Verify feature disabled
   - Wait for expiration
   - Verify feature re-enabled

3. **Hot-Reload Test**
   - Toggle kill-switches via API
   - Verify immediate effect
   - Verify config persistence

### Performance Tests

1. **Metrics Overhead**
   - Benchmark query latency with/without metrics
   - Ensure <5% performance impact
   - Test under load (10k qps)

2. **Logging Overhead**
   - Benchmark with different log levels
   - Measure DEBUG logging impact
   - Test log rotation performance

---

## Deployment & Rollout

### Backward Compatibility

- All new fields optional in config
- Existing configs work without changes
- Metrics gracefully handle nil pointer
- Logging uses existing logger instances

### Migration Guide

**Step 1**: Update main.go to pass metrics
```go
handler.SetMetrics(metrics)
blocklistMgr := blocklist.NewManager(cfg, logger, metrics)
cache := cache.New(&cfg.Cache, logger, metrics)
```

**Step 2**: Optional - Add duration kill-switches
```yaml
server:
  enable_blocklist: true
  # blocklist_disable_for: "5m"  # Optional: temporary disable
  enable_policies: true
```

**Step 3**: Verify metrics endpoint
```bash
curl http://localhost:9090/metrics | grep dns_
```

### Monitoring Recommendations

**Key Metrics to Alert On**:
```promql
# Cache hit rate < 50%
rate(dns_cache_hits[5m]) / (rate(dns_cache_hits[5m]) + rate(dns_cache_misses[5m])) < 0.5

# Blocked queries spike (>10% of total)
rate(dns_queries_blocked[5m]) / rate(dns_queries_total[5m]) > 0.1

# No forwarded queries (upstream down?)
rate(dns_queries_forwarded[5m]) == 0

# Blocklist size drop (update failed?)
blocklist_size < 10000
```

**Grafana Dashboard Additions**:
- Cache hit/miss rate graph
- Blocked vs allowed queries pie chart
- Forwarded queries by upstream
- Kill-switch state timeline
- Blocklist size over time

---

## Success Criteria

### Phase 1 (P0) Success
- ✅ DNSBlockedQueries metric recorded
- ✅ DNSForwardedQueries metric recorded
- ✅ Metrics visible in Prometheus
- ✅ No performance degradation (< 5% latency increase)

### Phase 2 (P1) Success
- ✅ DNSCacheHits/Misses metrics recorded
- ✅ BlocklistSize metric recorded
- ✅ CacheSize metric recorded
- ✅ All metrics have reasonable values

### Phase 3 (P2) Success
- ✅ Policy evaluation logs generated
- ✅ DNS action logs generated (INFO level)
- ✅ Storage errors logged
- ✅ Logs are structured and parseable

### Phase 4 (P3) Success
- ✅ Duration-based kill-switches work
- ✅ Auto-expiration and re-enable works
- ✅ API endpoints support duration
- ✅ Kill-switch metrics recorded

---

## Timeline

**Week 1**:
- Days 1-2: Phase 1 (P0 metrics)
- Days 3-5: Phase 2 (P1 cache/blocklist metrics)

**Week 2**:
- Days 1-3: Phase 3 (P2 logging)
- Days 4-5: Testing and bug fixes

**Week 3**:
- Days 1-3: Phase 4 (P3 duration kill-switches)
- Days 4-5: Integration testing, documentation

**Buffer**: 2-3 days for unexpected issues

---

## Related Documentation

- [Prometheus Metrics Guide](../operations/prometheus-metrics.md)
- [Logging Best Practices](../operations/logging.md)
- [Kill-Switch Operations](../operations/kill-switches.md)
- [v0.7.3 Technical Debt Plan](./v0.7.3-technical-debt-plan.md)

---

## Approvals

- [ ] Technical Lead Review
- [ ] Architecture Review
- [ ] Security Review (kill-switch API exposure)
- [ ] Performance Review (metrics overhead)

---

## Notes

- Consider adding OpenTelemetry tracing in future (currently no-op)
- May want to add rate limiting metrics in v0.7.5
- Consider per-client metrics for v0.8.0 (client management feature)
